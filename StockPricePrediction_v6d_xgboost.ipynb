{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "* 20191002: \n",
    "    * Given prices for the last N days, we do prediction for the next N+H days, where H is the forecast horizon\n",
    "    * Using xgboost\n",
    "* 20191004 - Diff from StockPricePrediction_v6_xgboost.ipynb:\n",
    "    * Instead of using mean and std from train set to do scaling/unscaling, use mean and std from the last N days to do scaling/unscaling\n",
    "* 20191007 - Diff from StockPricePrediction_v6a_xgboost.ipynb:\n",
    "    * Include a validation set to do hyperparameter tuning\n",
    "* 20191018 - Diff from StockPricePrediction_v6b_xgboost.ipynb:\n",
    "    * Instead of tuning N, we use a fixed N and observe the results\n",
    "* 20191021 - Diff from StockPricePrediction_v6c_xgboost.ipynb:\n",
    "    * Instead of using only features about price, introduce more features and observe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chart_studio\n",
    "!pip install fastai\n",
    "import chart_studio.plotly as py\n",
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import plotly.graph_objs as go\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "from fastai.tabular import add_datepart\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm_notebook\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# py.sign_in('<your-user-id>', '<your-api-key>') # sign in to plotly if you haven't done so\n",
    "\n",
    "#### Input params ##################\n",
    "folder = \"./data/\"\n",
    "filename = \"VTI_20130102_20181231.csv\"\n",
    "\n",
    "# Predicting on day 1008, date 2017-01-03 00:00:00\n",
    "# Predicting on day 1050, date 2017-03-06 00:00:00\n",
    "# Predicting on day 1092, date 2017-05-04 00:00:00\n",
    "# Predicting on day 1134, date 2017-07-05 00:00:00\n",
    "# Predicting on day 1176, date 2017-09-01 00:00:00\n",
    "# Predicting on day 1218, date 2017-11-01 00:00:00\n",
    "# Predicting on day 1260, date 2018-01-03 00:00:00\n",
    "# Predicting on day 1302, date 2018-03-06 00:00:00\n",
    "# Predicting on day 1344, date 2018-05-04 00:00:00\n",
    "# Predicting on day 1386, date 2018-07-05 00:00:00\n",
    "# Predicting on day 1428, date 2018-09-04 00:00:00\n",
    "# Predicting on day 1470, date 2018-11-01 00:00:00\n",
    "\n",
    "pred_day = 1008                # Predict for this day, for the next H-1 days. Note indexing of days start from 0.\n",
    "\n",
    "H = 21                         # Forecast horizon, in days. Note there are about 252 trading days in a year\n",
    "train_size = 252*3             # Use 3 years of data as train set. Note there are about 252 trading days in a year\n",
    "val_size = 252                 # Use 1 year of data as validation set\n",
    "N = 10                         # for feature at day t, we use lags from t-1, t-2, ..., t-N as features\n",
    "\n",
    "n_estimators = 100             # Number of boosted trees to fit. default = 100\n",
    "max_depth = 3                  # Maximum tree depth for base learners. default = 3\n",
    "learning_rate = 0.1            # Boosting learning rate (xgb’s “eta”). default = 0.1\n",
    "min_child_weight = 1           # Minimum sum of instance weight(hessian) needed in a child. default = 1\n",
    "subsample = 1                  # Subsample ratio of the training instance. default = 1\n",
    "colsample_bytree = 1           # Subsample ratio of columns when constructing each tree. default = 1\n",
    "colsample_bylevel = 1          # Subsample ratio of columns for each split, in each level. default = 1\n",
    "gamma = 0                      # Minimum loss reduction required to make a further partition on a leaf node of the tree. default=0\n",
    "\n",
    "model_seed = 100\n",
    "\n",
    "fontsize = 14\n",
    "ticklabelsize = 14\n",
    "\n",
    "# Plotly colors\n",
    "colors = [\n",
    "    '#1f77b4',  # muted blue\n",
    "    '#ff7f0e',  # safety orange\n",
    "    '#2ca02c',  # cooked asparagus green\n",
    "    '#d62728',  # brick red\n",
    "    '#9467bd',  # muted purple\n",
    "    '#8c564b',  # chestnut brown\n",
    "    '#e377c2',  # raspberry yogurt pink\n",
    "    '#7f7f7f',  # middle gray\n",
    "    '#bcbd22',  # curry yellow-green\n",
    "    '#17becf'   # blue-teal\n",
    "]\n",
    "\n",
    "####################################\n",
    "\n",
    "train_val_size = train_size + val_size # Size of train+validation set\n",
    "print(\"No. of days in train+validation set = \" + str(train_val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Compute mean absolute percentage error (MAPE)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def get_mae(a, b):\n",
    "    \"\"\"\n",
    "    Comp mean absolute error e_t = E[|a_t - b_t|]. a and b can be lists.\n",
    "    Returns a vector of len = len(a) = len(b)\n",
    "    \"\"\"\n",
    "    return np.mean(abs(np.array(a)-np.array(b)))\n",
    "\n",
    "def get_rmse(a, b):\n",
    "    \"\"\"\n",
    "    Comp RMSE. a and b can be lists.\n",
    "    Returns a scalar.\n",
    "    \"\"\"\n",
    "    return math.sqrt(np.mean((np.array(a)-np.array(b))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mov_avg_std(df, col, N):\n",
    "    \"\"\"\n",
    "    Given a dataframe, get mean and std dev at timestep t using values from t-1, t-2, ..., t-N.\n",
    "    Inputs\n",
    "        df         : dataframe. Can be of any length.\n",
    "        col        : name of the column you want to calculate mean and std dev\n",
    "        N          : get mean and std dev at timestep t using values from t-1, t-2, ..., t-N\n",
    "    Outputs\n",
    "        df_out     : same as df but with additional column containing mean and std dev\n",
    "    \"\"\"\n",
    "    mean_list = df[col].rolling(window = N, min_periods=1).mean() # len(mean_list) = len(df)\n",
    "    std_list = df[col].rolling(window = N, min_periods=1).std()   # first value will be NaN, because normalized by N-1\n",
    "    \n",
    "    # Add one timestep to the predictions\n",
    "    mean_list = np.concatenate((np.array([np.nan]), np.array(mean_list[:-1])))\n",
    "    std_list = np.concatenate((np.array([np.nan]), np.array(std_list[:-1])))\n",
    "    \n",
    "    # Append mean_list to df\n",
    "    df_out = df.copy()\n",
    "    df_out[col + '_mean'] = mean_list\n",
    "    df_out[col + '_std'] = std_list\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "def do_scaling(df, N):\n",
    "    \"\"\"\n",
    "    Do scaling for the adj_close and lag cols\n",
    "    \"\"\"\n",
    "    df.loc[:, 'adj_close_scaled'] = (df['adj_close'] - df['adj_close_mean']) / df['adj_close_std']\n",
    "    for n in range(N,0,-1):\n",
    "        df.loc[:, 'adj_close_scaled_lag_'+str(n)] = \\\n",
    "            (df['adj_close_lag_'+str(n)] - df['adj_close_mean']) / df['adj_close_std']\n",
    "        \n",
    "        # Remove adj_close_lag column which we don't need anymore\n",
    "        df.drop(['adj_close_lag_'+str(n)], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def pred_xgboost(model, X_test_ex_adj_close, N, H, prev_vals, prev_mean_val, prev_std_val):\n",
    "    \"\"\"\n",
    "    Do recursive forecasting using xgboost\n",
    "    Inputs\n",
    "        model              : the xgboost model\n",
    "        X_test_ex_adj_close: features of the test set, excluding adj_close_scaled values \n",
    "        N                  : for feature at day t, we use lags from t-1, t-2, ..., t-N as features\n",
    "        H                  : forecast horizon\n",
    "        prev_vals          : numpy array. If predict at time t, \n",
    "                             prev_vals will contain the N unscaled values at t-1, t-2, ..., t-N\n",
    "        prev_mean_val      : the mean of the unscaled values at t-1, t-2, ..., t-N\n",
    "        prev_std_val       : the std deviation of the unscaled values at t-1, t-2, ..., t-N\n",
    "    Outputs\n",
    "        Times series of predictions. Numpy array of shape (H,). This is unscaled.\n",
    "    \"\"\"\n",
    "    forecast = prev_vals.copy()\n",
    "\n",
    "    for n in range(H):\n",
    "        forecast_scaled = (forecast[-N:] - prev_mean_val) / prev_std_val\n",
    "        \n",
    "        # Create the features dataframe\n",
    "        X = X_test_ex_adj_close[n:n+1].copy()\n",
    "        for n in range(N,0,-1):\n",
    "            X.loc[:, \"adj_close_scaled_lag_\"+str(n)] = forecast_scaled[-n]\n",
    "        \n",
    "        # Do prediction\n",
    "        est_scaled = model.predict(X)\n",
    "        \n",
    "        # Unscale the prediction\n",
    "        forecast = np.concatenate([forecast, \n",
    "                                   np.array((est_scaled * prev_std_val) + prev_mean_val).reshape(1,)])\n",
    "        \n",
    "        # Comp. new mean and std\n",
    "        prev_mean_val = np.mean(forecast[-N:])\n",
    "        prev_std_val = np.std(forecast[-N:])\n",
    "           \n",
    "    return forecast[-H:]\n",
    "\n",
    "def train_pred_eval_model(X_train_scaled,\n",
    "                          y_train_scaled,\n",
    "                          X_test_ex_adj_close,\n",
    "                          y_test,\n",
    "                          N,\n",
    "                          H,\n",
    "                          prev_vals,\n",
    "                          prev_mean_val,\n",
    "                          prev_std_val,\n",
    "                          seed=100,\n",
    "                          n_estimators=100,\n",
    "                          max_depth=3,\n",
    "                          learning_rate=0.1,\n",
    "                          min_child_weight=1,\n",
    "                          subsample=1,\n",
    "                          colsample_bytree=1,\n",
    "                          colsample_bylevel=1,\n",
    "                          gamma=0):\n",
    "    '''\n",
    "    Train model, do prediction, scale back to original range and do evaluation\n",
    "    Use XGBoost here.\n",
    "    Inputs\n",
    "        X_train_scaled     : features for training. Scaled to have mean 0 and variance 1\n",
    "        y_train_scaled     : target for training. Scaled to have mean 0 and variance 1\n",
    "        X_test_ex_adj_close: features of the test set, excluding adj_close_scaled values \n",
    "        y_test             : target for test. Actual values, not scaled.\n",
    "        N                  : for feature at day t, we use lags from t-1, t-2, ..., t-N as features\n",
    "        H                  : forecast horizon\n",
    "        prev_vals          : numpy array. If predict at time t, \n",
    "                             prev_vals will contain the N unscaled values at t-1, t-2, ..., t-N\n",
    "        prev_mean_val      : the mean of the unscaled values at t-1, t-2, ..., t-N\n",
    "        prev_std_val       : the std deviation of the unscaled values at t-1, t-2, ..., t-N\n",
    "        seed               : model seed\n",
    "        n_estimators       : number of boosted trees to fit\n",
    "        max_depth          : maximum tree depth for base learners\n",
    "        learning_rate      : boosting learning rate (xgb’s “eta”)\n",
    "        min_child_weight   : minimum sum of instance weight(hessian) needed in a child\n",
    "        subsample          : subsample ratio of the training instance\n",
    "        colsample_bytree   : subsample ratio of columns when constructing each tree\n",
    "        colsample_bylevel  : subsample ratio of columns for each split, in each level\n",
    "        gamma              : \n",
    "    Outputs\n",
    "        rmse               : root mean square error of y_test and est\n",
    "        mape               : mean absolute percentage error of y_test and est\n",
    "        mae                : mean absolute error of y_test and est\n",
    "        est                : predicted values. Same length as y_test\n",
    "    '''\n",
    "\n",
    "    model = XGBRegressor(objective ='reg:squarederror',\n",
    "                         seed=model_seed,\n",
    "                         n_estimators=n_estimators,\n",
    "                         max_depth=max_depth,\n",
    "                         learning_rate=learning_rate,\n",
    "                         min_child_weight=min_child_weight,\n",
    "                         subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree,\n",
    "                         colsample_bylevel=colsample_bylevel,\n",
    "                         gamma=gamma)\n",
    "        \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    \n",
    "    # Get predicted labels and scale back to original range\n",
    "    est = pred_xgboost(model, X_test_ex_adj_close, N, H, prev_vals, prev_mean_val, prev_std_val)\n",
    "\n",
    "    # Calculate RMSE, MAPE, MAE\n",
    "    rmse = get_rmse(y_test, est)\n",
    "    mape = get_mape(y_test, est)\n",
    "    mae = get_mae(y_test, est)\n",
    "    \n",
    "    return rmse, mape, mae, est, model.feature_importances_\n",
    "\n",
    "def add_lags(df, N, lag_cols):\n",
    "    \"\"\"\n",
    "    Add lags up to N number of days to use as features\n",
    "    The lag columns are labelled as 'adj_close_lag_1', 'adj_close_lag_2', ... etc.\n",
    "    \"\"\"\n",
    "    # Use lags up to N number of days to use as features\n",
    "    df_w_lags = df.copy()\n",
    "    df_w_lags.loc[:, 'order_day'] = [x for x in list(range(len(df)))] # Add a column 'order_day' to indicate the order of the rows by date\n",
    "    merging_keys = ['order_day'] # merging_keys\n",
    "    shift_range = [x+1 for x in range(N)]\n",
    "    for shift in shift_range:\n",
    "        train_shift = df_w_lags[merging_keys + lag_cols].copy()\n",
    "    \n",
    "        # E.g. order_day of 0 becomes 1, for shift = 1.\n",
    "        # So when this is merged with order_day of 1 in df_w_lags, this will represent lag of 1.\n",
    "        train_shift['order_day'] = train_shift['order_day'] + shift\n",
    "    \n",
    "        foo = lambda x: '{}_lag_{}'.format(x, shift) if x in lag_cols else x\n",
    "        train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "        df_w_lags = pd.merge(df_w_lags, train_shift, on=merging_keys, how='left') #.fillna(0)\n",
    "    del train_shift\n",
    "    \n",
    "    return df_w_lags\n",
    "\n",
    "def get_error_metrics(df,\n",
    "                      train_size,\n",
    "                      N,\n",
    "                      H,\n",
    "                      seed=100,\n",
    "                      n_estimators=100,\n",
    "                      max_depth=3,\n",
    "                      learning_rate=0.1,\n",
    "                      min_child_weight=1,\n",
    "                      subsample=1,\n",
    "                      colsample_bytree=1,\n",
    "                      colsample_bylevel=1,\n",
    "                      gamma=0):\n",
    "    \"\"\"\n",
    "    Given a series consisting of both train+validation, do predictions of forecast horizon H on the validation set, \n",
    "    at H/2 intervals.\n",
    "    Inputs\n",
    "        df                 : train + val dataframe. len(df) = train_size + val_size\n",
    "        train_size         : size of train set\n",
    "        N                  : for feature at day t, we use lags from t-1, t-2, ..., t-N as features\n",
    "        H                  : forecast horizon\n",
    "        seed               : model seed\n",
    "        n_estimators       : number of boosted trees to fit\n",
    "        max_depth          : maximum tree depth for base learners\n",
    "        learning_rate      : boosting learning rate (xgb’s “eta”)\n",
    "        min_child_weight   : minimum sum of instance weight(hessian) needed in a child\n",
    "        subsample          : subsample ratio of the training instance\n",
    "        colsample_bytree   : subsample ratio of columns when constructing each tree\n",
    "        colsample_bylevel  : subsample ratio of columns for each split, in each level\n",
    "        gamma              : \n",
    "\n",
    "    Outputs\n",
    "        mean of rmse, mean of mape, mean of mae, dictionary of predictions\n",
    "    \"\"\"\n",
    "    rmse_list = [] # root mean square error\n",
    "    mape_list = [] # mean absolute percentage error\n",
    "    mae_list = []  # mean absolute error\n",
    "    preds_dict = {}\n",
    "    \n",
    "    # Add lags up to N number of days to use as features\n",
    "    df = add_lags(df, N, ['adj_close'])\n",
    "    \n",
    "    # Get mean and std dev at timestamp t using values from t-1, ..., t-N\n",
    "    df = get_mov_avg_std(df, 'adj_close', N)\n",
    "    \n",
    "    # Do scaling\n",
    "    df = do_scaling(df, N)\n",
    "    \n",
    "    # Get list of features\n",
    "    features_ex_adj_close = [\n",
    "        'year',\n",
    "        'month',\n",
    "        'week',\n",
    "        'day',\n",
    "        'dayofweek',\n",
    "        'dayofyear',\n",
    "        'is_month_end',\n",
    "        'is_month_start',\n",
    "        'is_quarter_end',\n",
    "        'is_quarter_start',\n",
    "        'is_year_end'\n",
    "    ]\n",
    "    features = features_ex_adj_close # features contain all features, including adj_close_lags\n",
    "    for n in range(N,0,-1):\n",
    "        features.append(\"adj_close_scaled_lag_\"+str(n))\n",
    "    \n",
    "    for i in range(train_size, len(df)-H+1, int(H/2)):\n",
    "        # Split into train and test\n",
    "        train = df[i-train_size:i].copy()\n",
    "        test = df[i:i+H].copy()\n",
    "    \n",
    "        # Drop the NaNs in train\n",
    "        train.dropna(axis=0, how='any', inplace=True)\n",
    "    \n",
    "        # Split into X and y\n",
    "        X_train_scaled = train[features]\n",
    "        y_train_scaled = train['adj_close_scaled']\n",
    "        X_test_ex_adj_close = test[features_ex_adj_close]\n",
    "        y_test = test['adj_close']\n",
    "        prev_vals = train[-N:]['adj_close'].to_numpy()\n",
    "        prev_mean_val = test.iloc[0]['adj_close_mean']\n",
    "        prev_std_val = test.iloc[0]['adj_close_std']\n",
    "            \n",
    "        rmse, mape, mae, est, _ = train_pred_eval_model(X_train_scaled,\n",
    "                                                        y_train_scaled,\n",
    "                                                        X_test_ex_adj_close,\n",
    "                                                        y_test,\n",
    "                                                        N,\n",
    "                                                        H,\n",
    "                                                        prev_vals,\n",
    "                                                        prev_mean_val,\n",
    "                                                        prev_std_val,\n",
    "                                                        seed=seed,\n",
    "                                                        n_estimators=n_estimators,\n",
    "                                                        max_depth=max_depth,\n",
    "                                                        learning_rate=learning_rate,\n",
    "                                                        min_child_weight=min_child_weight,\n",
    "                                                        subsample=subsample,\n",
    "                                                        colsample_bytree=colsample_bytree,\n",
    "                                                        colsample_bylevel=colsample_bylevel,\n",
    "                                                        gamma=gamma)\n",
    "#         print(\"N = \" + str(N) + \", i = \" + str(i) + \", rmse = \" + str(rmse) + \", mape = \" + str(mape) + \", mae = \" + str(mae))\n",
    "        \n",
    "        rmse_list.append(rmse)\n",
    "        mape_list.append(mape)\n",
    "        mae_list.append(mae)\n",
    "        preds_dict[i] = est\n",
    "    \n",
    "    return np.mean(rmse_list), np.mean(mape_list), np.mean(mae_list), preds_dict \n",
    "\n",
    "def get_error_metrics_one_pred(df,\n",
    "                               train_size,\n",
    "                               N,\n",
    "                               H,\n",
    "                               seed=100,\n",
    "                               n_estimators=100,\n",
    "                               max_depth=3,\n",
    "                               learning_rate=0.1,\n",
    "                               min_child_weight=1,\n",
    "                               subsample=1,\n",
    "                               colsample_bytree=1,\n",
    "                               colsample_bylevel=1,\n",
    "                               gamma=0):\n",
    "    \"\"\"\n",
    "    Given a series consisting of both train+test, do one prediction of forecast horizon H on the test set.\n",
    "    Inputs\n",
    "        df                 : train + test dataframe. len(df) = train_size + test_size\n",
    "        train_size         : size of train set\n",
    "        N                  : for feature at day t, we use lags from t-1, t-2, ..., t-N as features\n",
    "        H                  : forecast horizon\n",
    "        seed               : model seed\n",
    "        n_estimators       : number of boosted trees to fit\n",
    "        max_depth          : maximum tree depth for base learners\n",
    "        learning_rate      : boosting learning rate (xgb’s “eta”)\n",
    "        min_child_weight   : minimum sum of instance weight(hessian) needed in a child\n",
    "        subsample          : subsample ratio of the training instance\n",
    "        colsample_bytree   : subsample ratio of columns when constructing each tree\n",
    "        colsample_bylevel  : subsample ratio of columns for each split, in each level\n",
    "        gamma              : \n",
    "\n",
    "    Outputs\n",
    "        rmse, mape, mae, predictions\n",
    "    \"\"\"    \n",
    "    # Add lags up to N number of days to use as features\n",
    "    df = add_lags(df, N, ['adj_close'])\n",
    "    \n",
    "    # Get mean and std dev at timestamp t using values from t-1, ..., t-N\n",
    "    df = get_mov_avg_std(df, 'adj_close', N)\n",
    "    \n",
    "    # Do scaling\n",
    "    df = do_scaling(df, N)\n",
    "    \n",
    "    # Get list of features\n",
    "    features_ex_adj_close = [\n",
    "        'year',\n",
    "        'month',\n",
    "        'week',\n",
    "        'day',\n",
    "        'dayofweek',\n",
    "        'dayofyear',\n",
    "        'is_month_end',\n",
    "        'is_month_start',\n",
    "        'is_quarter_end',\n",
    "        'is_quarter_start',\n",
    "        'is_year_end'\n",
    "    ]\n",
    "    features = features_ex_adj_close # features contain all features, including adj_close_lags\n",
    "    for n in range(N,0,-1):\n",
    "        features.append(\"adj_close_scaled_lag_\"+str(n))\n",
    "    \n",
    "    # Split into train and test\n",
    "    train = df[:train_size].copy()\n",
    "    test = df[train_size:train_size+H].copy()\n",
    "    \n",
    "    # Drop the NaNs in train\n",
    "    train.dropna(axis=0, how='any', inplace=True)\n",
    "    \n",
    "    # Split into X and y\n",
    "    X_train_scaled = train[features]\n",
    "    y_train_scaled = train['adj_close_scaled']\n",
    "    X_test_ex_adj_close = test[features_ex_adj_close]\n",
    "    y_test = test['adj_close']\n",
    "    prev_vals = train[-N:]['adj_close'].to_numpy()\n",
    "    prev_mean_val = test.iloc[0]['adj_close_mean']\n",
    "    prev_std_val = test.iloc[0]['adj_close_std']\n",
    "            \n",
    "    rmse, mape, mae, est, feature_importances = train_pred_eval_model(X_train_scaled,\n",
    "                                                                      y_train_scaled,\n",
    "                                                                      X_test_ex_adj_close,\n",
    "                                                                      y_test,\n",
    "                                                                      N,\n",
    "                                                                      H,\n",
    "                                                                      prev_vals,\n",
    "                                                                      prev_mean_val,\n",
    "                                                                      prev_std_val,\n",
    "                                                                      seed=seed,\n",
    "                                                                      n_estimators=n_estimators,\n",
    "                                                                      max_depth=max_depth,\n",
    "                                                                      learning_rate=learning_rate,\n",
    "                                                                      min_child_weight=min_child_weight,\n",
    "                                                                      subsample=subsample,\n",
    "                                                                      colsample_bytree=colsample_bytree,\n",
    "                                                                      colsample_bylevel=colsample_bylevel,\n",
    "                                                                      gamma=gamma)\n",
    "    \n",
    "    return rmse, mape, mae, est, feature_importances, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folder+filename, sep = \",\")\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df.loc[:, 'Date'] = pd.to_datetime(df['Date'],format='%Y-%m-%d')\n",
    "\n",
    "# Change all column headings to be lower case, and remove spacing\n",
    "df.columns = [str(x).lower().replace(' ', '_') for x in df.columns]\n",
    "\n",
    "# Sort by datetime\n",
    "df.sort_values(by='date', inplace=True, ascending=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns which you can't use as features\n",
    "df.drop(['open', 'high', 'low', 'close', 'volume'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with plotly\n",
    "data = [go.Scatter(\n",
    "            x = df['date'],\n",
    "            y = df['adj_close'],\n",
    "            mode = 'lines')]\n",
    "\n",
    "layout = dict(xaxis = dict(title = 'date'),\n",
    "              yaxis = dict(title = 'USD'))\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create features\n",
    "add_datepart(df, 'date', drop=False)\n",
    "df.drop('Elapsed', axis=1, inplace=True)  # don't need this\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all column headings to be lower case, and remove spacing\n",
    "df.columns = [str(x).lower().replace(' ', '_') for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert year to categorical feature, based on alphabetical order\n",
    "df.loc[:, 'year'] = LabelEncoder().fit_transform(df['year'])\n",
    "df[15:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of nulls for each column\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute the average price for each month\n",
    "avg_price_mth = df.groupby(\"month\").agg({'adj_close': 'mean'}).reset_index()\n",
    "\n",
    "# Plot \n",
    "data = [go.Scatter(\n",
    "            x = avg_price_mth['month'],\n",
    "            y = avg_price_mth['adj_close'],\n",
    "            mode = 'markers',\n",
    "            marker=dict(\n",
    "                color='LightSkyBlue',\n",
    "                size=15,\n",
    "                line=dict(\n",
    "                color='MediumPurple',\n",
    "                width=2\n",
    "                ))\n",
    "        )]\n",
    "\n",
    "layout = dict(xaxis = dict(title = 'month'),\n",
    "              yaxis = dict(title = 'average adjusted closing price (USD)'))\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_avg_price_mth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average price for each day of month\n",
    "avg_price_day = df.groupby(\"day\").agg({'adj_close': 'mean'}).reset_index()\n",
    "\n",
    "# Plot \n",
    "data = [go.Scatter(\n",
    "            x = avg_price_day['day'],\n",
    "            y = avg_price_day['adj_close'],\n",
    "            mode = 'markers',\n",
    "            marker=dict(\n",
    "                color='LightSkyBlue',\n",
    "                size=15,\n",
    "                line=dict(\n",
    "                color='MediumPurple',\n",
    "                width=2\n",
    "                ))\n",
    "        )]\n",
    "\n",
    "layout = dict(xaxis = dict(title = 'day of month'),\n",
    "              yaxis = dict(title = 'average adjusted closing price (USD)'))\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_avg_price_dayofmonth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average price for each day of week\n",
    "avg_price_dayofweek = df.groupby(\"dayofweek\").agg({'adj_close': 'mean'}).reset_index()\n",
    "\n",
    "# Plot \n",
    "data = [go.Scatter(\n",
    "            x = avg_price_dayofweek['dayofweek'],\n",
    "            y = avg_price_dayofweek['adj_close'],\n",
    "            mode = 'markers',\n",
    "            marker=dict(\n",
    "                color='LightSkyBlue',\n",
    "                size=15,\n",
    "                line=dict(\n",
    "                color='MediumPurple',\n",
    "                width=2\n",
    "                ))\n",
    "        )]\n",
    "\n",
    "layout = dict(xaxis = dict(title = 'day of week'),\n",
    "              yaxis = dict(title = 'average adjusted closing price (USD)'))\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_avg_price_dayofweek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lags \n",
    "df_lags = add_lags(df, N, ['adj_close'])\n",
    "df_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation\n",
    "features = [\n",
    "        'adj_close',\n",
    "        'year',\n",
    "        'month',\n",
    "        'week',\n",
    "        'day',\n",
    "        'dayofweek',\n",
    "        'dayofyear',\n",
    "        'is_month_end',\n",
    "        'is_month_start',\n",
    "        'is_quarter_end',\n",
    "        'is_quarter_start',\n",
    "        'is_year_end',\n",
    "        'is_year_start'\n",
    "]\n",
    "for n in range(N,0,-1):\n",
    "    features.append(\"adj_close_lag_\"+str(n))\n",
    "        \n",
    "corr_matrix = df_lags[features].corr()\n",
    "corr_matrix[\"adj_close\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation for lag features only\n",
    "features = ['adj_close']\n",
    "for n in range(1,N+1,1):\n",
    "    features.append(\"adj_close_lag_\"+str(n))\n",
    "        \n",
    "corr_matrix = df_lags[features].corr()\n",
    "\n",
    "z_list = []\n",
    "for feat in features:\n",
    "    z_list.append(corr_matrix.loc[:, feat][features])\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "                   z=z_list,\n",
    "                   x=features,\n",
    "                   y=features))\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_corr_matrix_lags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation for date features only\n",
    "features = [\n",
    "        'adj_close',\n",
    "        'year',\n",
    "        'month',\n",
    "        'week',\n",
    "        'day',\n",
    "        'dayofweek',\n",
    "        'dayofyear',\n",
    "        'is_month_end',\n",
    "        'is_month_start',\n",
    "        'is_quarter_end',\n",
    "        'is_quarter_start',\n",
    "        'is_year_end',\n",
    "        'is_year_start'\n",
    "]\n",
    "        \n",
    "corr_matrix = df_lags[features].corr()\n",
    "\n",
    "z_list = []\n",
    "for feat in features:\n",
    "    z_list.append(corr_matrix.loc[:, feat][features])\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "                   z=z_list,\n",
    "                   x=features,\n",
    "                   y=features))\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_corr_matrix_dates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting on day %d, date %s, with forecast horizon H = %d\" % (pred_day, df.iloc[pred_day]['date'], H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[pred_day-train_val_size:pred_day-val_size].copy()\n",
    "val = df[pred_day-val_size:pred_day].copy()\n",
    "train_val = df[pred_day-train_val_size:pred_day].copy()\n",
    "test = df[pred_day:pred_day+H].copy()\n",
    "print(\"train.shape = \" + str(train.shape))\n",
    "print(\"val.shape = \" + str(val.shape))\n",
    "print(\"train_val.shape = \" + str(train_val.shape))\n",
    "print(\"test.shape = \" + str(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for a specific H (forecast horizon) and a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get error metrics on validation set before hyperparameter tuning\n",
    "rmse_bef_tuning, mape_bef_tuning, mae_bef_tuning, preds_dict = \\\n",
    "                                                      get_error_metrics(train_val,\n",
    "                                                                        train_size,\n",
    "                                                                        N,\n",
    "                                                                        H,\n",
    "                                                                        seed=model_seed,\n",
    "                                                                        n_estimators=n_estimators,\n",
    "                                                                        max_depth=max_depth,\n",
    "                                                                        learning_rate=learning_rate,\n",
    "                                                                        min_child_weight=min_child_weight,\n",
    "                                                                        subsample=subsample,\n",
    "                                                                        colsample_bytree=colsample_bytree,\n",
    "                                                                        colsample_bylevel=colsample_bylevel,\n",
    "                                                                        gamma=gamma)\n",
    "print(\"RMSE = %0.3f\" % rmse_bef_tuning)\n",
    "print(\"MAPE = %0.3f%%\" % mape_bef_tuning)\n",
    "print(\"MAE = %0.3f%%\" % mae_bef_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation predictions\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=train['date'], \n",
    "                         y=train['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='train',\n",
    "                         line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=val['date'], \n",
    "                         y=val['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='validation',\n",
    "                         line=dict(color='orange')))\n",
    "fig.add_trace(go.Scatter(x=test['date'], \n",
    "                         y=test['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='test',\n",
    "                         line=dict(color='green')))\n",
    "\n",
    "# Plot the predictions\n",
    "n = 0\n",
    "for key in preds_dict:\n",
    "    fig.add_trace(go.Scatter(x=train_val[key:key+H]['date'], \n",
    "                             y=preds_dict[key],\n",
    "                             mode='lines',\n",
    "                             name='predictions',\n",
    "                             line=dict(color=colors[n%len(colors)])))\n",
    "    n = n + 1\n",
    "\n",
    "fig.update_layout(yaxis=dict(title='USD'),\n",
    "                  xaxis=dict(title='date'))\n",
    "fig.update_xaxes(range=['2017-10-16', '2018-11-12'])\n",
    "fig.update_yaxes(range=[127, 157])\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_xgboost_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do prediction on test set\n",
    "test_rmse_bef_tuning, test_mape_bef_tuning, test_mae_bef_tuning, est, feature_importances, features = \\\n",
    "                                            get_error_metrics_one_pred(df[pred_day-train_val_size:pred_day+H],\n",
    "                                                                       train_size+val_size,\n",
    "                                                                       N,\n",
    "                                                                       H,\n",
    "                                                                       seed=model_seed,\n",
    "                                                                       n_estimators=n_estimators,\n",
    "                                                                       max_depth=max_depth,\n",
    "                                                                       learning_rate=learning_rate,\n",
    "                                                                       min_child_weight=min_child_weight,\n",
    "                                                                       subsample=subsample,\n",
    "                                                                       colsample_bytree=colsample_bytree,\n",
    "                                                                       colsample_bylevel=colsample_bylevel,\n",
    "                                                                       gamma=gamma)\n",
    "\n",
    "print(\"RMSE = %0.3f\" % test_rmse_bef_tuning)\n",
    "print(\"MAPE = %0.3f%%\" % test_mape_bef_tuning)\n",
    "print(\"MAE = %0.3f\" % test_mae_bef_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test predictions\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=train['date'], \n",
    "                         y=train['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='train',\n",
    "                         line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=val['date'], \n",
    "                         y=val['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='validation',\n",
    "                         line=dict(color='orange')))\n",
    "fig.add_trace(go.Scatter(x=test['date'], \n",
    "                         y=test['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='test',\n",
    "                         line=dict(color='green')))\n",
    "fig.add_trace(go.Scatter(x=test[:H]['date'], \n",
    "                         y=est,\n",
    "                         mode='lines',\n",
    "                         name='predictions',\n",
    "                         line=dict(color='red')))\n",
    "fig.update_layout(yaxis=dict(title='USD'),\n",
    "                  xaxis=dict(title='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a list of the features and their importance scores\n",
    "imp = list(zip(features, feature_importances))\n",
    "imp.sort(key=lambda tup: tup[1], reverse=False) \n",
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for a specific H (forecast horizon) and a specific date, with hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a constant for N here\n",
    "N_opt = N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning n_estimators (default=100) and max_depth (default=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_label = 'n_estimators'\n",
    "param_list = range(1, 61, 2)\n",
    "\n",
    "param2_label = 'max_depth'\n",
    "param2_list = [2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "error_rate = defaultdict(list)\n",
    "\n",
    "tic = time.time()\n",
    "for param in tqdm_notebook(param_list):\n",
    "    for param2 in param2_list:\n",
    "        rmse_mean, mape_mean, mae_mean, _ = get_error_metrics(train_val,\n",
    "                                                              train_size,\n",
    "                                                              N_opt,\n",
    "                                                              H,\n",
    "                                                              seed=model_seed,\n",
    "                                                              n_estimators=param,\n",
    "                                                              max_depth=param2,\n",
    "                                                              learning_rate=learning_rate,\n",
    "                                                              min_child_weight=min_child_weight,\n",
    "                                                              subsample=subsample,\n",
    "                                                              colsample_bytree=colsample_bytree,\n",
    "                                                              colsample_bylevel=colsample_bylevel,\n",
    "                                                              gamma=gamma)\n",
    "    \n",
    "        # Collect results\n",
    "        error_rate[param_label].append(param)\n",
    "        error_rate[param2_label].append(param2)\n",
    "        error_rate['rmse'].append(rmse_mean)\n",
    "        error_rate['mape'].append(mape_mean)\n",
    "        error_rate['mae'].append(mae_mean)\n",
    "    \n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "toc = time.time()\n",
    "print(\"Minutes taken = {0:.2f}\".format((toc-tic)/60.0))\n",
    "\n",
    "error_rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance versus params\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "temp = error_rate[error_rate[param2_label]==param2_list[0]]\n",
    "ax = temp.plot(x=param_label, y='rmse', style='bs-', grid=True)\n",
    "legend_list = [param2_label + '_' + str(param2_list[0])]\n",
    "\n",
    "color_list = ['r', 'g', 'k', 'y', 'm', 'c', '0.75']\n",
    "for i in range(1,len(param2_list)):\n",
    "    temp = error_rate[error_rate[param2_label]==param2_list[i]]\n",
    "    ax = temp.plot(x=param_label, y='rmse', color=color_list[i%len(color_list)], marker='s', grid=True, ax=ax)\n",
    "    legend_list.append(param2_label + '_' + str(param2_list[i]))\n",
    "\n",
    "ax.set_xlabel(param_label)\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "# ax.set_ylim([0, 20])\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.legend(legend_list, loc='center left', bbox_to_anchor=(1.0, 0.5)) # positions legend outside figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2, using RMSE\n",
    "temp = error_rate[error_rate['rmse'] == error_rate['rmse'].min()]\n",
    "n_estimators_opt = temp['n_estimators'].values[0]\n",
    "max_depth_opt = temp['max_depth'].values[0]\n",
    "print(\"min RMSE = %0.3f\" % error_rate['rmse'].min())\n",
    "print(\"optimum params = \")\n",
    "n_estimators_opt, max_depth_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2, using MAPE\n",
    "temp = error_rate[error_rate['mape'] == error_rate['mape'].min()]\n",
    "print(\"min MAPE = %0.3f%%\" % error_rate['mape'].min())\n",
    "print(\"optimum params = \")\n",
    "temp['n_estimators'].values[0], temp['max_depth'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning learning_rate(default=0.1) and min_child_weight(default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_label = 'learning_rate'\n",
    "param_list = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "\n",
    "param2_label = 'min_child_weight'\n",
    "param2_list = range(5, 21, 1)\n",
    "\n",
    "error_rate = defaultdict(list)\n",
    "\n",
    "tic = time.time()\n",
    "for param in tqdm_notebook(param_list):\n",
    "    for param2 in param2_list:\n",
    "        rmse_mean, mape_mean, mae_mean, _ = get_error_metrics(train_val,\n",
    "                                                              train_size,\n",
    "                                                              N_opt,\n",
    "                                                              H,\n",
    "                                                              seed=model_seed,\n",
    "                                                              n_estimators=n_estimators_opt,\n",
    "                                                              max_depth=max_depth_opt,\n",
    "                                                              learning_rate=param,\n",
    "                                                              min_child_weight=param2,\n",
    "                                                              subsample=subsample,\n",
    "                                                              colsample_bytree=colsample_bytree,\n",
    "                                                              colsample_bylevel=colsample_bylevel,\n",
    "                                                              gamma=gamma)\n",
    "    \n",
    "        # Collect results\n",
    "        error_rate[param_label].append(param)\n",
    "        error_rate[param2_label].append(param2)\n",
    "        error_rate['rmse'].append(rmse_mean)\n",
    "        error_rate['mape'].append(mape_mean)\n",
    "        error_rate['mae'].append(mae_mean)\n",
    "    \n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "toc = time.time()\n",
    "print(\"Minutes taken = {0:.2f}\".format((toc-tic)/60.0))\n",
    "\n",
    "error_rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance versus params\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "temp = error_rate[error_rate[param2_label]==param2_list[0]]\n",
    "ax = temp.plot(x=param_label, y='rmse', style='bs-', grid=True)\n",
    "legend_list = [param2_label + '_' + str(param2_list[0])]\n",
    "\n",
    "color_list = ['r', 'g', 'k', 'y', 'm', 'c', '0.75']\n",
    "for i in range(1,len(param2_list)):\n",
    "    temp = error_rate[error_rate[param2_label]==param2_list[i]]\n",
    "    ax = temp.plot(x=param_label, y='rmse', color=color_list[i%len(color_list)], marker='s', grid=True, ax=ax)\n",
    "    legend_list.append(param2_label + '_' + str(param2_list[i]))\n",
    "\n",
    "ax.set_xlabel(param_label)\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "# ax.set_ylim([0, 4])\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.legend(legend_list, loc='center left', bbox_to_anchor=(1.0, 0.5)) # positions legend outside figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2, using RMSE\n",
    "temp = error_rate[error_rate['rmse'] == error_rate['rmse'].min()]\n",
    "learning_rate_opt = temp['learning_rate'].values[0]\n",
    "min_child_weight_opt = temp['min_child_weight'].values[0]\n",
    "print(\"min RMSE = %0.3f\" % error_rate['rmse'].min())\n",
    "print(\"optimum params = \")\n",
    "learning_rate_opt, min_child_weight_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2, using MAPE\n",
    "temp = error_rate[error_rate['mape'] == error_rate['mape'].min()]\n",
    "print(\"min MAPE = %0.3f%%\" % error_rate['mape'].min())\n",
    "print(\"optimum params = \")\n",
    "temp['learning_rate'].values[0], temp['min_child_weight'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning XGBoost - subsample(default=1) and gamma(default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_label = 'subsample'\n",
    "param_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "param2_label = 'gamma'\n",
    "param2_list = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "error_rate = defaultdict(list)\n",
    "\n",
    "tic = time.time()\n",
    "for param in tqdm_notebook(param_list):\n",
    "    for param2 in param2_list:\n",
    "        rmse_mean, mape_mean, mae_mean, _ = get_error_metrics(train_val,\n",
    "                                                              train_size,\n",
    "                                                              N_opt,\n",
    "                                                              H,\n",
    "                                                              seed=model_seed,\n",
    "                                                              n_estimators=n_estimators_opt,\n",
    "                                                              max_depth=max_depth_opt,\n",
    "                                                              learning_rate=learning_rate_opt,\n",
    "                                                              min_child_weight=min_child_weight_opt,\n",
    "                                                              subsample=param,\n",
    "                                                              colsample_bytree=colsample_bytree,\n",
    "                                                              colsample_bylevel=colsample_bylevel,\n",
    "                                                              gamma=param2)\n",
    "\n",
    "        # Collect results\n",
    "        error_rate[param_label].append(param)\n",
    "        error_rate[param2_label].append(param2)\n",
    "        error_rate['rmse'].append(rmse_mean)\n",
    "        error_rate['mape'].append(mape_mean)\n",
    "        error_rate['mae'].append(mae_mean)\n",
    "    \n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "toc = time.time()\n",
    "print(\"Minutes taken = {0:.2f}\".format((toc-tic)/60.0))\n",
    "\n",
    "error_rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance versus params\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "temp = error_rate[error_rate[param2_label]==param2_list[0]]\n",
    "ax = temp.plot(x=param_label, y='rmse', style='bs-', grid=True)\n",
    "legend_list = [param2_label + '_' + str(param2_list[0])]\n",
    "\n",
    "color_list = ['r', 'g', 'k', 'y', 'm', 'c', '0.75']\n",
    "for i in range(1,len(param2_list)):\n",
    "    temp = error_rate[error_rate[param2_label]==param2_list[i]]\n",
    "    ax = temp.plot(x=param_label, y='rmse', color=color_list[i%len(color_list)], marker='s', grid=True, ax=ax)\n",
    "    legend_list.append(param2_label + '_' + str(param2_list[i]))\n",
    "\n",
    "ax.set_xlabel(param_label)\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.legend(legend_list, loc='center left', bbox_to_anchor=(1.0, 0.5)) # positions legend outside figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2, using RMSE\n",
    "temp = error_rate[error_rate['rmse'] == error_rate['rmse'].min()]\n",
    "subsample_opt = temp['subsample'].values[0]\n",
    "gamma_opt = temp['gamma'].values[0]\n",
    "print(\"min RMSE = %0.3f\" % error_rate['rmse'].min())\n",
    "print(\"optimum params = \")\n",
    "subsample_opt, gamma_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2, using MAPE\n",
    "temp = error_rate[error_rate['mape'] == error_rate['mape'].min()]\n",
    "print(\"min MAPE = %0.3f%%\" % error_rate['mape'].min())\n",
    "print(\"optimum params = \")\n",
    "temp['subsample'].values[0], temp['gamma'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning colsample_bytree(default=1) and colsample_bylevel(default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_label = 'colsample_bytree'\n",
    "param_list = [0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "param2_label = 'colsample_bylevel'\n",
    "param2_list = [0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "error_rate = defaultdict(list)\n",
    "\n",
    "tic = time.time()\n",
    "for param in tqdm_notebook(param_list):    \n",
    "    for param2 in param2_list:\n",
    "        rmse_mean, mape_mean, mae_mean, _ = get_error_metrics(train_val,\n",
    "                                                              train_size,\n",
    "                                                              N_opt,\n",
    "                                                              H,\n",
    "                                                              seed=model_seed,\n",
    "                                                              n_estimators=n_estimators_opt,\n",
    "                                                              max_depth=max_depth_opt,\n",
    "                                                              learning_rate=learning_rate_opt,\n",
    "                                                              min_child_weight=min_child_weight_opt,\n",
    "                                                              subsample=subsample_opt,\n",
    "                                                              colsample_bytree=param,\n",
    "                                                              colsample_bylevel=param2,\n",
    "                                                              gamma=gamma_opt)\n",
    "\n",
    "    \n",
    "        # Collect results\n",
    "        error_rate[param_label].append(param)\n",
    "        error_rate[param2_label].append(param2)\n",
    "        error_rate['rmse'].append(rmse_mean)\n",
    "        error_rate['mape'].append(mape_mean)\n",
    "        error_rate['mae'].append(mae_mean)\n",
    "    \n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "toc = time.time()\n",
    "print(\"Minutes taken = {0:.2f}\".format((toc-tic)/60.0))\n",
    "\n",
    "error_rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance versus params\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "temp = error_rate[error_rate[param2_label]==param2_list[0]]\n",
    "ax = temp.plot(x=param_label, y='rmse', style='bs-', grid=True)\n",
    "legend_list = [param2_label + '_' + str(param2_list[0])]\n",
    "\n",
    "color_list = ['r', 'g', 'k', 'y', 'm', 'c', '0.75']\n",
    "for i in range(1,len(param2_list)):\n",
    "    temp = error_rate[error_rate[param2_label]==param2_list[i]]\n",
    "    ax = temp.plot(x=param_label, y='rmse', color=color_list[i%len(color_list)], marker='s', grid=True, ax=ax)\n",
    "    legend_list.append(param2_label + '_' + str(param2_list[i]))\n",
    "\n",
    "ax.set_xlabel(param_label)\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.legend(legend_list, loc='center left', bbox_to_anchor=(1.0, 0.5)) # positions legend outside figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2, using RMSE\n",
    "temp = error_rate[error_rate['rmse'] == error_rate['rmse'].min()]\n",
    "colsample_bytree_opt = temp['colsample_bytree'].values[0]\n",
    "colsample_bylevel_opt = temp['colsample_bylevel'].values[0]\n",
    "print(\"min RMSE = %0.3f\" % error_rate['rmse'].min())\n",
    "print(\"optimum params = \")\n",
    "colsample_bytree_opt, colsample_bylevel_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2, using MAPE\n",
    "temp = error_rate[error_rate['mape'] == error_rate['mape'].min()]\n",
    "print(\"min MAPE = %0.3f%%\" % error_rate['mape'].min())\n",
    "print(\"optimum params = \")\n",
    "temp['colsample_bytree'].values[0], temp['colsample_bylevel'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get error metrics on validation set after hyperparameter tuning\n",
    "rmse_aft_tuning, mape_aft_tuning, mae_aft_tuning, preds_dict = \\\n",
    "                                                      get_error_metrics(train_val,\n",
    "                                                                        train_size,\n",
    "                                                                        N_opt,\n",
    "                                                                        H,\n",
    "                                                                        seed=model_seed,\n",
    "                                                                        n_estimators=n_estimators_opt,\n",
    "                                                                        max_depth=max_depth_opt,\n",
    "                                                                        learning_rate=learning_rate_opt,\n",
    "                                                                        min_child_weight=min_child_weight_opt,\n",
    "                                                                        subsample=subsample_opt,\n",
    "                                                                        colsample_bytree=colsample_bytree_opt,\n",
    "                                                                        colsample_bylevel=colsample_bylevel_opt,\n",
    "                                                                        gamma=gamma_opt)\n",
    "print(\"RMSE = %0.3f\" % rmse_aft_tuning)\n",
    "print(\"MAPE = %0.3f%%\" % mape_aft_tuning)\n",
    "print(\"MAE = %0.3f\" % mae_aft_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation predictions\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=train['date'], \n",
    "                         y=train['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='train',\n",
    "                         line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=val['date'], \n",
    "                         y=val['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='validation',\n",
    "                         line=dict(color='orange')))\n",
    "fig.add_trace(go.Scatter(x=test['date'], \n",
    "                         y=test['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='test',\n",
    "                         line=dict(color='green')))\n",
    "\n",
    "# Plot the predictions\n",
    "n = 0\n",
    "for key in preds_dict:\n",
    "    fig.add_trace(go.Scatter(x=train_val[key:key+H]['date'], \n",
    "                             y=preds_dict[key],\n",
    "                             mode='lines',\n",
    "                             name='predictions',\n",
    "                             line=dict(color=colors[n%len(colors)])))\n",
    "    n = n + 1\n",
    "\n",
    "fig.update_layout(yaxis=dict(title='USD'),\n",
    "                  xaxis=dict(title='date'))\n",
    "fig.update_xaxes(range=['2017-10-16', '2018-11-12'])\n",
    "fig.update_yaxes(range=[127, 157])\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_xgboost_val_aft_tune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do prediction on test set\n",
    "test_rmse_aft_tuning, test_mape_aft_tuning, test_mae_aft_tuning, est, feature_importances, features = \\\n",
    "                                            get_error_metrics_one_pred(df[pred_day-train_val_size:pred_day+H],\n",
    "                                                                       train_size+val_size,\n",
    "                                                                       N_opt,\n",
    "                                                                       H,\n",
    "                                                                       seed=model_seed,\n",
    "                                                                       n_estimators=n_estimators_opt,\n",
    "                                                                       max_depth=max_depth_opt,\n",
    "                                                                       learning_rate=learning_rate_opt,\n",
    "                                                                       min_child_weight=min_child_weight_opt,\n",
    "                                                                       subsample=subsample_opt,\n",
    "                                                                       colsample_bytree=colsample_bytree_opt,\n",
    "                                                                       colsample_bylevel=colsample_bylevel_opt,\n",
    "                                                                       gamma=gamma_opt)\n",
    "\n",
    "\n",
    "print(\"RMSE = %0.3f\" % test_rmse_aft_tuning)\n",
    "print(\"MAPE = %0.3f%%\" % test_mape_aft_tuning)\n",
    "print(\"MAE = %0.3f\" % test_mae_aft_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test predictions\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=train['date'], \n",
    "                         y=train['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='train',\n",
    "                         line=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=val['date'], \n",
    "                         y=val['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='validation',\n",
    "                         line=dict(color='orange')))\n",
    "fig.add_trace(go.Scatter(x=test['date'], \n",
    "                         y=test['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='test',\n",
    "                         line=dict(color='green')))\n",
    "fig.add_trace(go.Scatter(x=test[:H]['date'], \n",
    "                         y=est,\n",
    "                         mode='lines',\n",
    "                         name='predictions',\n",
    "                         line=dict(color='red')))\n",
    "fig.update_layout(yaxis=dict(title='USD'),\n",
    "                  xaxis=dict(title='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a list of the features and their importance scores\n",
    "imp = list(zip(features, feature_importances))\n",
    "imp.sort(key=lambda tup: tup[1], reverse=False) \n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the importance scores as a bar chart\n",
    "fig = go.Figure(go.Bar(\n",
    "            x=[item[1] for item in imp[-10:]],\n",
    "            y=[item[0] for item in imp[-10:]],\n",
    "            orientation='h'))\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_xgboost_imp_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned params and before and after error metrics\n",
    "d = {'param': ['n_estimators', 'max_depth', 'learning_rate', 'min_child_weight', 'subsample', 'colsample_bytree', 'colsample_bylevel', 'gamma', 'val_rmse', 'val_mape', 'val_mae'],\n",
    "     'before_tuning': [n_estimators, max_depth, learning_rate, min_child_weight, subsample, colsample_bytree, colsample_bylevel, gamma, rmse_bef_tuning, mape_bef_tuning, mae_bef_tuning],\n",
    "     'after_tuning': [n_estimators_opt, max_depth_opt, learning_rate_opt, min_child_weight_opt, subsample_opt, colsample_bytree_opt, colsample_bylevel_opt, gamma_opt, rmse_aft_tuning, mape_aft_tuning, mae_aft_tuning]}\n",
    "tuned_params = pd.DataFrame(d)\n",
    "tuned_params = tuned_params.round(3)\n",
    "tuned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put tuned_params into pickle\n",
    "pickle.dump(tuned_params, open(\"./out/v6d_tuned_params_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.load(open(\"./out/v6d_tuned_params_\" + \"2017-03-06\" + \".pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc1 = time.time()\n",
    "print(\"Total minutes taken = {0:.2f}\".format((toc1-tic1)/60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting on day %d, date %s, with forecast horizon H = %d\" % (pred_day, df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\"), H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_bef_tuning, rmse_aft_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_rmse_bef_tuning, test_rmse_aft_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put results into pickle\n",
    "pickle.dump(rmse_bef_tuning, open(\"./out/v6d_val_rmse_bef_tuning_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))\n",
    "pickle.dump(rmse_aft_tuning, open(\"./out/v6d_val_rmse_aft_tuning_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))\n",
    "pickle.dump(test_rmse_bef_tuning, open(\"./out/v6d_test_rmse_bef_tuning_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))\n",
    "pickle.dump(test_mape_bef_tuning, open(\"./out/v6d_test_mape_bef_tuning_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))\n",
    "pickle.dump(test_mae_bef_tuning, open(\"./out/v6d_test_mae_bef_tuning_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))\n",
    "pickle.dump(test_rmse_aft_tuning, open(\"./out/v6d_test_rmse_aft_tuning_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))\n",
    "pickle.dump(test_mape_aft_tuning, open(\"./out/v6d_test_mape_aft_tuning_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))\n",
    "pickle.dump(test_mae_aft_tuning, open(\"./out/v6d_test_mae_aft_tuning_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))\n",
    "pickle.dump(est, open(\"./out/v6d_test_est_aft_tuning_\" + df.iloc[pred_day]['date'].strftime(\"%Y-%m-%d\") + \".pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate results\n",
    "# H = 21                         # Forecast horizon, in days. Note there are about 252 trading days in a year\n",
    "# train_size = 252*3             # Use 3 years of data as train set. Note there are about 252 trading days in a year\n",
    "# val_size = 252                 # Use 1 year of data as validation set\n",
    "# N = 10                          # for feature at day t, we use lags from t-1, t-2, ..., t-N as features\n",
    "results = defaultdict(list)\n",
    "ests = {} # the predictions\n",
    "date_list = ['2017-01-03',\n",
    "             '2017-03-06',\n",
    "             '2017-05-04',\n",
    "             '2017-07-05',\n",
    "             '2017-09-01',\n",
    "             '2017-11-01',\n",
    "             '2018-01-03',\n",
    "             '2018-03-06',\n",
    "             '2018-05-04',\n",
    "             '2018-07-05',\n",
    "             '2018-09-04',\n",
    "             '2018-11-01'\n",
    "            ]\n",
    "for date in date_list:\n",
    "    results['date'].append(date)\n",
    "    results['val_rmse_bef_tuning'].append(pickle.load(open( \"./out/v6d_val_rmse_bef_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    results['val_rmse_aft_tuning'].append(pickle.load(open( \"./out/v6d_val_rmse_aft_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    results['test_rmse_bef_tuning'].append(pickle.load(open( \"./out/v6d_test_rmse_bef_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    results['test_rmse_aft_tuning'].append(pickle.load(open( \"./out/v6d_test_rmse_aft_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    results['test_mape_bef_tuning'].append(pickle.load(open( \"./out/v6d_test_mape_bef_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    results['test_mape_aft_tuning'].append(pickle.load(open( \"./out/v6d_test_mape_aft_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    results['test_mae_bef_tuning'].append(pickle.load(open( \"./out/v6d_test_mae_bef_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    results['test_mae_aft_tuning'].append(pickle.load(open( \"./out/v6d_test_mae_aft_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    ests[date] = pickle.load(open( \"./out/v6d_test_est_aft_tuning_\" + date + \".pickle\", \"rb\"))\n",
    "    \n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a condensed dataframe of the above\n",
    "results_short = defaultdict(list)\n",
    "hyperparam_list = ['n_estimators', \n",
    "                   'max_depth', \n",
    "                   'learning_rate', \n",
    "                   'min_child_weight',\n",
    "#                    'subsample',\n",
    "#                    'colsample_bytree',\n",
    "#                    'colsample_bylevel',\n",
    "#                    'gamma'\n",
    "                  ]\n",
    "\n",
    "for date in date_list:\n",
    "    results_short['date'].append(date)\n",
    "    results_short['RMSE'].append(pickle.load(open( \"./out/v6d_test_rmse_aft_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    results_short['MAPE(%)'].append(pickle.load(open( \"./out/v6d_test_mape_aft_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    results_short['MAE'].append(pickle.load(open( \"./out/v6d_test_mae_aft_tuning_\" + date + \".pickle\", \"rb\")))\n",
    "    \n",
    "    tuned_params = pickle.load(open(\"./out/v6d_tuned_params_\" + date + \".pickle\", \"rb\"))\n",
    "    for hyperparam in hyperparam_list:\n",
    "        results_short[hyperparam].append(tuned_params[tuned_params['param']==hyperparam]['after_tuning'].values[0])\n",
    "\n",
    "    \n",
    "results_short = pd.DataFrame(results_short)\n",
    "results_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all predictions\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=df['date'], \n",
    "                         y=df['adj_close'],\n",
    "                         mode='lines',\n",
    "                         name='adj_close',\n",
    "                         line=dict(color='blue')))\n",
    "\n",
    "# Plot the predictions\n",
    "n = 0\n",
    "for key in ests:\n",
    "    i = df[df['date']==key].index[0]\n",
    "    fig.add_trace(go.Scatter(x=df[i:i+H]['date'], \n",
    "                             y=ests[key],\n",
    "                             mode='lines',\n",
    "                             name='predictions',\n",
    "                             line=dict(color=colors[n%len(colors)])))\n",
    "    n = n + 1\n",
    "\n",
    "fig.update_layout(yaxis=dict(title='USD'),\n",
    "                  xaxis=dict(title='date'))\n",
    "fig.update_xaxes(range=['2017-01-03', '2018-12-28'])\n",
    "fig.update_yaxes(range=[110, 150])\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_xgboost_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter plot of actual values vs. predictions\n",
    "fig = go.Figure()\n",
    "\n",
    "n = 0\n",
    "for key in ests:\n",
    "    i = df[df['date']==key].index[0]\n",
    "    fig.add_trace(go.Scatter(x=df[i:i+H]['adj_close'], \n",
    "                             y=ests[key],\n",
    "                             mode='markers',\n",
    "                             name='predictions',\n",
    "                             line=dict(color=colors[n%len(colors)])))\n",
    "    n = n + 1\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(110, 155, 1)),\n",
    "                         y=list(range(110, 155, 1)),\n",
    "                         mode='lines',\n",
    "                         name='actual values',\n",
    "                         line=dict(color='blue')))\n",
    "\n",
    "fig.update_layout(yaxis=dict(title='forecasts'),\n",
    "                  xaxis=dict(title='adj_close'))\n",
    "py.iplot(fig, filename='StockPricePrediction_v6d_xgboost_actuals_vs_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results with benchmark\n",
    "all_results = pd.DataFrame({'Method': ['Last value',  'XGBoost w/o date features', 'XGBoost w date features'],\n",
    "                            'RMSE': [2.53, 2.32, 2.42],\n",
    "                            'MAPE(%)': [1.69, 1.53, 1.61],\n",
    "                            'MAE': [2.26, 2.05, 2.15]})\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
