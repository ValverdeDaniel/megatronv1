{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ce4fa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_loc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12672/2531813427.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[0mout_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_loc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0min_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_X5_trn_xgb_param_performance.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[0mres5_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[0mout_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_loc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0min_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_X5_trn_xgb_param_bestset.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out_loc' is not defined"
     ]
    }
   ],
   "source": [
    "# #Example to show that it now also works with just a single column or single row\n",
    "# mat <- matrix(1:100, byrow=T, nrow=10)\n",
    "# column_annotation <- sample(c(\"red\", \"blue\", \"green\"), 10, replace=T)\n",
    "# column_annotation <- as.matrix(column_annotation)\n",
    "# colnames(column_annotation) <- c(\"Variable X\")\n",
    "\n",
    "# row_annotation <- sample(c(\"red\", \"blue\", \"green\"), 10, replace=T)\n",
    "# row_annotation <- as.matrix(t(row_annotation))\n",
    "# rownames(row_annotation) <- c(\"Variable Y\")\n",
    "\n",
    "# heatmap.3(mat, RowSideColors=row_annotation, ColSideColors=column_annotation)\n",
    "\n",
    "# XGBoost classifier python code\n",
    "def expand_grid(dictionary):\n",
    "    return pd.DataFrame([row for row in product(*dictionary.values())],columns=dictionary.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #max_delta_step 1-10 might help logistic regression\n",
    "    #scale_pos_weight [default=1] control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider: sum(negative instances) / sum(positive instances\n",
    "    #sum(Y5_trn==0)/sum(Y5_trn==1)     Out[1725]: 0.46522585270920824\n",
    "    # Prediction: prob of class 1  (cutoff of 0.5, 0.1 -> class0, 0.9 -> class1)\n",
    "    obj='binary:logistic'\n",
    "    #nthread=4\n",
    "    num_cv=5\n",
    "\n",
    "    grid = {'eta': [0.001, 0.01], #seq(2, 10, 1)/ntrees,\n",
    "        'max_depth': [4, 6, 8],\n",
    "        'reg_lambda': [1, 5, 10],\n",
    "        #'min_child_weight': [1, 5],\n",
    "        'colsample_bytree': [0.5, 0.75, 1],\n",
    "        'subsample': [0.4, 0.6, 0.8, 1],\n",
    "        'max_delta_step': [1, 5, 10],\n",
    "        'scale_pos_weight': [0.5, 1, 1.5]}\n",
    "    \n",
    "    '''\n",
    "    grid = {'eta': [0.01], #seq(2, 10, 1)/ntrees,\n",
    "        'max_depth': [4],\n",
    "        'reg_lambda': [1],\n",
    "        'colsample_bytree': [0.5],\n",
    "        'subsample': [0.4],\n",
    "        'max_delta_step': [1],\n",
    "        'scale_pos_weight': [0.5]}\n",
    "    '''    \n",
    "    \n",
    "    param_grid=expand_grid(grid)  # Expand grid\n",
    "    num_param=param_grid.shape[0] # Get number of parameters\n",
    "    \n",
    "    out_name=out_loc+in_name+'_xgb_param_grid.csv'\n",
    "    param_grid.to_csv(out_name, index=False)\n",
    "    \n",
    "                                    \n",
    "    # Get performance results: validation & CV training of the training partitions\n",
    "    res5_df = pd.DataFrame(columns=['val_aucpr','val_acc','val_tn','val_fp','val_fn','val_tp',\n",
    "                                 'cv_aucpr','cv_acc','cv_tn','cv_fp','cv_fn','cv_tp'])\n",
    "    max5_auc = 0\n",
    "    best5_param = pd.DataFrame()\n",
    "    best5_res = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    # Parameter tuning using CV\n",
    "    for i, row in param_grid.iterrows():\n",
    "        print('--- Processing parameter ',i+1,'of',num_param,'(',round((i+1)/num_param*100,2),'%) ---')\n",
    "        \n",
    "        xgb = XGBClassifier(objective=obj, n_estimators=5000,                       \n",
    "                            eta=row['eta'], \n",
    "                            max_depth = int(row['max_depth']), \n",
    "                            reg_lambda = row['reg_lambda'], \n",
    "                            colsample_bytree = row['colsample_bytree'], \n",
    "                            subsample = row['subsample'], \n",
    "                            max_delta_step = row['max_delta_step'],\n",
    "                            scale_pos_weight = row['scale_pos_weight'])\n",
    "        \n",
    "    \n",
    "        # Cross-validation (Stratified)\n",
    "        kf = StratifiedKFold(n_splits=num_cv)\n",
    "        #-- CV: AHI5 --\n",
    "        for cv_idx, val_idx in kf.split(X5_trn, Y5_trn):\n",
    "            X5_cv, Y5_cv   = X5_trn.iloc[cv_idx,:], Y5_trn.iloc[cv_idx]\n",
    "            X5_val, Y5_val = X5_trn.iloc[val_idx,:], Y5_trn.iloc[val_idx]\n",
    "            eval_set = [(X5_val, Y5_val)]\n",
    "            \n",
    "            #xgb.fit(X5_cv, Y5_cv, eval_set=eval_set, early_stopping_rounds=5, eval_metric=\"logloss\", verbose=False)\n",
    "            #xgb.fit(X5_cv, Y5_cv, eval_set=eval_set, early_stopping_rounds=5, eval_metric=\"map\", verbose=False)\n",
    "            xgb.fit(X5_cv, Y5_cv, eval_set=eval_set, early_stopping_rounds=5, eval_metric=\"aucpr\", verbose=False)\n",
    "            \n",
    "            # Probability (AUC for precision & recall)\n",
    "            Yhat5_val = xgb.predict_proba(X5_val)[:,1] # prob of class 1\n",
    "            Yhat5_cv = xgb.predict_proba(X5_cv)[:,1]   # prob of class 1\n",
    "        \n",
    "            pre_val, rec_val, thre = precision_recall_curve(Y5_val, Yhat5_val) # a vector\n",
    "            pre_cv, rec_cv, thre = precision_recall_curve(Y5_cv, Yhat5_cv)     # a vector\n",
    "        \n",
    "            auc_val = auc(rec_val, pre_val) # a value\n",
    "            auc_cv = auc(rec_cv, pre_cv)    # a value\n",
    "        \n",
    "            # Binary (TN, FP, FN, TP & Acc)\n",
    "            Yhat5_val = xgb.predict(X5_val) # binary prediction {0,1}\n",
    "            Yhat5_cv = xgb.predict(X5_cv)  # binary prediction {0,1}\n",
    "            \n",
    "            acc_val = accuracy_score(Y5_val, Yhat5_val)\n",
    "            acc_cv = accuracy_score(Y5_cv, Yhat5_cv)\n",
    "        \n",
    "            tn_val, fp_val, fn_val, tp_val = confusion_matrix(Y5_val, Yhat5_val).ravel()\n",
    "            tn_cv, fp_cv, fn_cv, tp_cv = confusion_matrix(Y5_cv, Yhat5_cv).ravel()\n",
    "            \n",
    "            res5_df.loc[i] = np.around([auc_val, acc_val, tn_val, fp_val, fn_val, tp_val,\n",
    "                                        auc_cv, acc_cv, tn_cv, fp_cv, fn_cv, tp_cv], 3)\n",
    "    \n",
    "#       Get current best model. \n",
    "#       Note: should consider using average of 5fold CV's best\n",
    "            if auc_val > max5_auc:\n",
    "                best5_param = pd.DataFrame(row)\n",
    "                best5_res = res5_df.loc[i]\n",
    "                max5_auc = auc_val\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "out_name=out_loc+in_name+'_X5_trn_xgb_param_performance.csv'\n",
    "res5_df.to_csv(out_name, header=True, index=True)\n",
    "out_name=out_loc+in_name+'_X5_trn_xgb_param_bestset.csv'\n",
    "best5_param.to_csv(out_name, header=True, index=True)\n",
    "out_name=out_loc+in_name+'_X5_trn_xgb_param_best_res.csv'\n",
    "best5_res.to_csv(out_name, header=True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
