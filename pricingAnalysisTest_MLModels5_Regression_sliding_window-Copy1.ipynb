{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly\n",
    "import pandas as pd\n",
    "# !pip install pandas_ta\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import requests\n",
    "import plotly as py\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn as sk\n",
    "import sklearn.preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import  (StandardScaler, MinMaxScaler, LabelBinarizer)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import *\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "# !pip install graphviz\n",
    "# import graphviz\n",
    "# import chart_studio.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geckoReq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31152/2637060699.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m \u001b[0mmydf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_builder_clean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumDaysBack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheCoins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmycom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower_macd_ema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper_macd_ema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrigger_macd_ema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31152/2637060699.py\u001b[0m in \u001b[0;36mdf_builder_clean\u001b[1;34m(days, interval, coins, window, mycom, lower_macd_ema, upper_macd_ema, trigger_macd_ema)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#builds initial dataframe with ethereum as first market but just to log the dates we are working with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeckoReq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prices'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'geckoReq' is not defined"
     ]
    }
   ],
   "source": [
    "#manipulatable variables\n",
    "numDaysBack = str(365*5) #for daily you can go back multiple years worth, for daily you can only go back 90 days\n",
    "myInterval = 'daily' # options are daily or hourly\n",
    "theCoins = ['ethereum'] #can add more than one coin if you like\n",
    "window_length = 14\n",
    "mycom = 0.4\n",
    "lower_macd_ema = 12\n",
    "upper_macd_ema = 26\n",
    "trigger_macd_ema = 9\n",
    "\n",
    "\n",
    "def df_builder_clean(days, interval, coins, window, mycom, lower_macd_ema, upper_macd_ema, trigger_macd_ema):\n",
    "    #manipulatable variables\n",
    "    numDaysBack = days #for daily you can go back multiple years worth, for daily you can only go back 90 days\n",
    "    myInterval = interval # options are daily or hourly\n",
    "    theCoins = coins\n",
    "    window_length = window\n",
    "\n",
    "    #builds initial dataframe with ethereum as first market but just to log the dates we are working with\n",
    "    r = requests.get(geckoReq).json()\n",
    "    ts = r['prices'][0][0]\n",
    "    ts = ts/1000\n",
    "    HistPricesList = []\n",
    "    for i in range(len(r['prices'])):\n",
    "        currentUnix = r['prices'][i][0] \n",
    "        price = r['prices'][i][1]\n",
    "        currentUnix = currentUnix/1000\n",
    "#         currentTS = datetime.datetime.fromtimestamp(currentUnix).strftime(\"%d-%m-%Y %H:%M:%S\") #adding dd-mm-yyyy hours minutes seconds\n",
    "        currentTS = datetime.datetime.fromtimestamp(currentUnix).strftime(\"%m-%d-%Y\") #just the date mm-dd-yyyy\n",
    "        HistPricesList.append([currentTS])\n",
    "    global df\n",
    "    df = pd.DataFrame(HistPricesList, columns = ['date'])\n",
    "\n",
    "    \n",
    "    #looping through each coin and adding in all data points and input variables\n",
    "    for coin in theCoins:\n",
    "        price_data(coin)\n",
    "        add_ewm(coin, mycom)\n",
    "        add_rsi(coin, window_length)\n",
    "        add_macd(coin, lower_macd_ema, upper_macd_ema, trigger_macd_ema)\n",
    "        print('just added: ', coin)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.set_index('date')\n",
    "#     print('r')\n",
    "#     display(r)\n",
    "    return df\n",
    "\n",
    "\n",
    "def price_data(coin):\n",
    "    global df\n",
    "    # geckoReq = 'https://api.coingecko.com/api/v3/coins/ethereum/market_chart?vs_currency=usd&days=60&interval=daily'\n",
    "    geckoReq = 'https://api.coingecko.com/api/v3/coins/'+coin+'/market_chart?vs_currency=usd&days='+numDaysBack+'&interval='+myInterval+''\n",
    "\n",
    "    r = requests.get(geckoReq).json()\n",
    "    ts = r['prices'][0][0]\n",
    "    # print(ts)\n",
    "    ts = ts/1000\n",
    "    print(datetime.datetime.fromtimestamp(ts).strftime(\"%m-%d-%Y\"))\n",
    "    # print('prices length',len(r['prices']))\n",
    "    HistPricesList = []\n",
    "    for i in range(len(r['prices'])):\n",
    "        currentUnix = r['prices'][i][0] \n",
    "        price = r['prices'][i][1]\n",
    "        volume = r['total_volumes'][i][1]\n",
    "        currentUnix = currentUnix/1000\n",
    "        currentTS = datetime.datetime.fromtimestamp(currentUnix).strftime(\"%m-%d-%Y\")\n",
    "    #     print('price: ', price, 'TS: ', currentTS)\n",
    "        HistPricesList.append([currentTS, price, volume])\n",
    "    #     currentUnix = currentTS\n",
    "#         print(HistPricesList)\n",
    "    dfCoin = pd.DataFrame(HistPricesList, columns = ['date', coin, coin+'_volume'])\n",
    "#     print('dfCoin')\n",
    "#     display(dfCoin)\n",
    "    df = pd.merge(df, dfCoin[coin], left_on = df['date'], right_on=dfCoin['date']).drop(['key_0'], axis = 1)\n",
    "    df = pd.merge(df, dfCoin[coin+'_volume'], left_on = df['date'], right_on=dfCoin['date']).drop(['key_0'], axis = 1)\n",
    "    \n",
    "def add_ewm(coin, mycom):\n",
    "    df[coin+'_ewm'] = df[coin].ewm(com=mycom).mean()\n",
    "    \n",
    "def add_rsi(coin, window_length):\n",
    "    global df\n",
    "    df['diff'] = df[coin].diff(1)\n",
    "    df['gain'] = df['diff'].clip(lower=0).round(2)\n",
    "    df['loss'] = df['diff'].clip(upper=0).abs().round(2)\n",
    "    \n",
    "    # Get initial Averages\n",
    "    df['avg_gain'] = df['gain'].rolling(window=window_length, min_periods=window_length).mean()[:window_length+1]\n",
    "    df['avg_loss'] = df['loss'].rolling(window=window_length, min_periods=window_length).mean()[:window_length+1]\n",
    "\n",
    "    # Get WMS averages\n",
    "    # Average Gains\n",
    "    for i, row in enumerate(df['avg_gain'].iloc[window_length+1:]):\n",
    "        df['avg_gain'].iloc[i + window_length + 1] =\\\n",
    "            (df['avg_gain'].iloc[i + window_length] *\n",
    "             (window_length - 1) +\n",
    "             df['gain'].iloc[i + window_length + 1])\\\n",
    "            / window_length\n",
    "    # Average Losses\n",
    "    for i, row in enumerate(df['avg_loss'].iloc[window_length+1:]):\n",
    "        df['avg_loss'].iloc[i + window_length + 1] =\\\n",
    "            (df['avg_loss'].iloc[i + window_length] *\n",
    "             (window_length - 1) +\n",
    "             df['loss'].iloc[i + window_length + 1])\\\n",
    "            / window_length\n",
    "        \n",
    "    df['rs'] = df['avg_gain'] / df['avg_loss']\n",
    "    \n",
    "    df['rsi'] = 100 - (100 / (1.0 + df['rs']))\n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.drop(['gain', 'loss', 'avg_loss', 'avg_gain', 'rs'], axis = 1)\n",
    "    \n",
    "    #renaming diff and rsi columns\n",
    "    dict = {'diff': coin+'_diff',\n",
    "        'rsi': coin+'_rsi'}\n",
    "    df.rename(columns=dict,\n",
    "              inplace=True)\n",
    "\n",
    "def add_macd(coin, lower_macd_ema, upper_macd_ema, trigger_macd_ema):\n",
    "    global df\n",
    "    #get ema for lower\n",
    "    k = df[coin].ewm(span=lower_macd_ema, adjust = False, min_periods = lower_macd_ema).mean()\n",
    "\n",
    "    #get ema for upper\n",
    "    d = df[coin].ewm(span=upper_macd_ema, adjust=False, min_periods=upper_macd_ema).mean()\n",
    "\n",
    "    macd = k-d\n",
    "    \n",
    "    # Get the 9-Day EMA of the MACD for the Trigger line\n",
    "    macd_s = macd.ewm(span=trigger_macd_ema, adjust=False, min_periods=trigger_macd_ema).mean()\n",
    "    # Calculate the difference between the MACD - Trigger for the Convergence/Divergence value\n",
    "    macd_h = macd - macd_s\n",
    "    # Add all of our new values for the MACD to the dataframe\n",
    "    df['macd'] = df.index.map(macd)\n",
    "    df['macd_h'] = df.index.map(macd_h)\n",
    "    df['macd_s'] = df.index.map(macd_s)\n",
    "\n",
    "\n",
    "\n",
    "mydf = pd.DataFrame(df_builder_clean(numDaysBack, myInterval, theCoins, window_length, mycom, lower_macd_ema, upper_macd_ema, trigger_macd_ema))\n",
    "display(mydf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.dropna(inplace=True)\n",
    "myCols = ['ethereum', 'ethereum_volume', 'ethereum_ewm', 'ethereum_rsi', 'macd', 'macd_h', 'macd_s', 'ethereum_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = mydf[myCols]\n",
    "display(my_data)\n",
    "my_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression, scaled, shift data to predict off of yesterdays info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = my_data[['ethereum_volume', 'ethereum_ewm', 'ethereum_rsi', 'macd', 'ethereum_diff']]\n",
    "X_raw = my_data[['ethereum_volume', 'ethereum_ewm', 'ethereum_rsi', 'macd', 'macd_h', 'macd_s', 'ethereum_diff']]\n",
    "y = my_data['ethereum']\n",
    "scaler=StandardScaler()\n",
    "# Drop first row of prices\n",
    "y.drop(index=y.index[0], \n",
    "        axis=0, \n",
    "        inplace=True)\n",
    "#dropping last row of features\n",
    "X_raw.drop(index=X_raw.index[-1], \n",
    "        axis=0, \n",
    "        inplace=True)\n",
    "X=scaler.fit_transform(X_raw)\n",
    "display(X)\n",
    "# X = X.shift(1, freq='d')\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .1, random_state=42)\n",
    "X_train = X[:-60]\n",
    "X_test = X[-60:]\n",
    "y_train = y[:-60]\n",
    "y_test = y[-60:]\n",
    "print('X_train: ')\n",
    "print(X_train.shape)\n",
    "print('X_test: ')\n",
    "print(X_test.shape)\n",
    "print('y_train: ')\n",
    "print(y_train.shape)\n",
    "print('y_test: ')\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "print('linear regression with no scaling')\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "# The mean squared error\n",
    "print(\"Root Mean squared error: %.2f\" % math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "y_check1 = pd.DataFrame(y_test)\n",
    "# print(y_check1)\n",
    "y_check1['pred_linear_reg']= y_pred\n",
    "print(y_check1)\n",
    "plt.plot(y_check1.index,y_check1['ethereum'], color = 'black')\n",
    "plt.plot(y_check1.index,y_check1['pred_linear_reg'], color = 'green')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST SCALED Shifted 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = my_data[['ethereum_volume', 'ethereum_ewm', 'ethereum_rsi', 'macd', 'ethereum_diff']]\n",
    "X_raw = my_data[['ethereum_volume', 'ethereum_ewm', 'ethereum_rsi', 'macd', 'macd_h', 'macd_s', 'ethereum_diff']]\n",
    "y = my_data['ethereum']\n",
    "scaler=StandardScaler()\n",
    "# Drop first row of prices\n",
    "y.drop(index=y.index[0], \n",
    "        axis=0, \n",
    "        inplace=True)\n",
    "#dropping last row of features\n",
    "X_raw.drop(index=X_raw.index[-1], \n",
    "        axis=0, \n",
    "        inplace=True)\n",
    "X=scaler.fit_transform(X_raw)\n",
    "display(X)\n",
    "# X = X.shift(1, freq='d')\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .1, random_state=42)\n",
    "X_train = X[:-60]\n",
    "X_test = X[-60:]\n",
    "y_train = y[:-60]\n",
    "y_test = y[-60:]\n",
    "print('X_train: ')\n",
    "print(X_train.shape)\n",
    "print('X_test: ')\n",
    "print(X_test.shape)\n",
    "print('y_train: ')\n",
    "print(y_train.shape)\n",
    "print('y_test: ')\n",
    "print(y_test.shape)\n",
    "\n",
    "xg_reg=xgb.XGBRegressor(objective='reg:squarederror',colsample_bytree=0.3, learning_rate=0.1,\n",
    "                        max_depth=5,alpha=10,n_estimators=10)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds=xg_reg.predict(X_test)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,preds))\n",
    "# print(preds)\n",
    "# print(y_check1)\n",
    "print('xgb rmse: ', rmse)\n",
    "# y_check1['pred_xgb']= preds\n",
    "# plt.plot(y_check1.index,y_check1['ethereum'], color = 'black')\n",
    "# plt.plot(y_check1.index,y_check1['pred_linear_reg'], color = 'green')\n",
    "# plt.plot(y_check1.index,y_check1['pred_xgb'], color = 'blue')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "#     'n_estimators': range(0, 1000, 50),\n",
    "    'n_estimators': [10,50,60,200,500,1000],\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "#     'eval_metric': ['rmse', 'mae', 'mape']\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xg_reg,\n",
    "    param_grid=parameters,\n",
    "#     scoring = 'roc_auc',\n",
    "    n_jobs = 10,\n",
    "    cv = 5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_\n",
    "grid_search.best_estimator_.fit(X_train, y_train)\n",
    "y_pred_train = grid_search.best_estimator_.predict(X_train)\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "print('xgb rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(grid_search.best_estimator_)\n",
    "plt.rcParams['figure.figsize']=[16,10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split and create sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=list(mydf['ethereum'])\n",
    "# display(seq)\n",
    "\n",
    "window_size = 10\n",
    "sliding_window=[]\n",
    "for i in range(len(seq) - window_size + 1):\n",
    "    sliding_window.append(seq[i: i + window_size])\n",
    "    \n",
    "# print(sliding_window)\n",
    "\n",
    "sliding_df = pd.DataFrame(sliding_window)\n",
    "display(sliding_df)\n",
    "y = sliding_df[0]\n",
    "X = sliding_df.drop(columns=[0]) \n",
    "X=scaler.fit_transform(X)\n",
    "# print('X')\n",
    "# display(X)\n",
    "# print('y')\n",
    "# display(y)\n",
    "# X = X.shift(1, freq='d')\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=42)\n",
    "X_train = X[:-60]\n",
    "X_test = X[-60:]\n",
    "y_train = y[:-60]\n",
    "y_test = y[-60:]\n",
    "print('X_train: ')\n",
    "print(X_train.shape)\n",
    "print('X_test: ')\n",
    "print(X_test.shape)\n",
    "print('y_train: ')\n",
    "print(y_train.shape)\n",
    "print('y_test: ')\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost on sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xg_reg=xgb.XGBRegressor(objective='reg:squarederror',colsample_bytree=0.3, learning_rate=0.1,\n",
    "                        max_depth=5,alpha=10,n_estimators=10)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds=xg_reg.predict(X_test)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,preds))\n",
    "# print(preds)\n",
    "# print(y_check1)\n",
    "print('xgb rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "#     'n_estimators': range(0, 1000, 50),\n",
    "    'n_estimators': [10,50,60,200,500,1000],\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "#     'eval_metric': ['rmse', 'mae', 'mape']\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xg_reg,\n",
    "    param_grid=parameters,\n",
    "#     scoring = 'roc_auc',\n",
    "    n_jobs = 10,\n",
    "    cv = 5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_\n",
    "grid_search.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "print('xgb rmse: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(grid_search.best_estimator_)\n",
    "plt.rcParams['figure.figsize']=[16,10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#linear regression on sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('linear regression with no scaling')\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "# The mean squared error\n",
    "print(\"Root Mean squared error: %.2f\" % math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "# print(y_check1)\n",
    "y_test_df['pred_linear_reg']= y_pred\n",
    "# print(y_check1)\n",
    "plt.plot(y_test_df.index,y_test_df[0], color = 'black')\n",
    "plt.plot(y_test_df.index,y_test_df['pred_linear_reg'], color = 'green')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "deb2fc3b7a79c00288712747267ecd2a2b552c99a2db2f88ef7b866d6588bf0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
